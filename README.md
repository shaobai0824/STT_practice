# 
# 🧠 理論基礎：Transformer 架構在 Whisper 中的應用
# ==============================================================================
# 
# 第一部分：Transformer 編碼器-解碼器架構
# ------------------------------------------------------------------------------
# Whisper 採用標準的 Transformer 編碼器-解碼器架構：
# 
# 1.1 編碼器 (Encoder) 的角色：理解聲音
# - 輸入：梅爾頻譜圖轉換成的向量序列 [batch_size, 80, 3000]
#   * 80: 梅爾頻率特徵維度 (Mel Frequency Features)
#   * 3000: 時間步數 (Time Steps, 約30秒音訊)
# - 核心機制：自注意力機制 (Self-Attention)
# - 輸出：富含上下文資訊的隱藏狀態 [batch_size, 3000, 768]
#   * 768: Whisper-small 的隱藏維度
# 
# 1.2 解碼器 (Decoder) 的角色：生成文字
# - 輸入：編碼器隱藏狀態 + 已生成文字序列
# - 核心機制：
#   * 遮罩式自注意力 (Masked Self-Attention)
#   * 交叉注意力 (Cross-Attention) - 連接編碼器和解碼器
# - 輸出：下一個文字 Token 的機率分佈
# 
# 第二部分：從聲波到向量 - 特徵提取流程
# ------------------------------------------------------------------------------
# 2.1 音訊重採樣：原始音訊 → 16,000 Hz 標準化
# 2.2 STFT：時域訊號 → 頻域訊號 (25ms 音框)
# 2.3 梅爾轉換：線性頻譜 → 梅爾頻譜圖 (80維)
# 2.4 對數轉換：能量值 → 對數梅爾頻譜圖
# 
# 第三部分：學習過程 - 微調與權重調整
# ------------------------------------------------------------------------------
# 3.1 調整的權重：
# - ✅ Transformer 編碼器所有參數 (自注意力、前饋神經網路)
# - ✅ Transformer 解碼器所有參數 (遮罩式自注意力、交叉注意力)
# - ❌ WhisperTokenizer (固定對照表)
# - ❌ WhisperFeatureExtractor (數學公式，無可學習權重)
# 
# 3.2 訓練迴圈：前向傳播 → 計算損失 → 反向傳播 → 更新權重
# 更新公式：W_new = W_old - η·∇L (η=1e-5 學習率)
# 