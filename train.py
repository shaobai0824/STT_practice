# ==============================================================================
# æª”æ¡ˆï¼štrain_final.py
# æè¿°ï¼šä¸€å€‹å®Œæ•´ã€é«˜æ•ˆã€ç©©å¥çš„ Whisper ä¸­æ–‡èªéŸ³è¾¨è­˜æ¨¡å‹å¾®èª¿æµç¨‹ã€‚
# æ ¸å¿ƒç­–ç•¥ï¼š
# 1. å³æ™‚è½‰æ› (.with_transform)ï¼šå¾¹åº•è§£æ±ºè¨˜æ†¶é«”ä¸è¶³èˆ‡é è™•ç†éä¹…çš„å•é¡Œã€‚
# 2. èƒŒæ™¯é å– (dataloader_num_workers)ï¼šè§£æ±º CPU èˆ‡ I/O ç“¶é ¸ï¼Œæœ€å¤§åŒ– GPU ä½¿ç”¨ç‡ã€‚
# 3. å…¨åŸŸå®šç¾© (Global Scope)ï¼šè§£æ±ºå¤šæ ¸å¿ƒè™•ç†æ™‚çš„ pickling éŒ¯èª¤ã€‚
# 4. æ™ºæ…§çºŒç·´ (Smart Resuming)ï¼šè‡ªå‹•å¾ä¸Šæ¬¡çš„æª¢æŸ¥é»æ¢å¾©è¨“ç·´ã€‚
# 5. ä¸­æ–‡å„ªåŒ–è©•ä¼°ï¼šä½¿ç”¨ CER å’Œèªæ„ç›¸ä¼¼åº¦æ›¿ä»£ WERï¼Œæ›´é©åˆä¸­æ–‡èªéŸ³è¾¨è­˜ã€‚
# 6. å¿«é€Ÿå±•ç¤ºå„ªåŒ–ï¼šæ ¹æ“šç ”ç©¶çµæœèª¿æ•´è¨“ç·´æ­¥æ•¸ï¼Œ1000æ­¥é©åˆå¿«é€Ÿå±•ç¤ºã€‚
# ==============================================================================

import os
from dataclasses import dataclass
from functools import partial
from typing import Any, Dict, List, Union

import evaluate
# --- æ–°å¢ï¼šä¸­æ–‡è©•ä¼°ç›¸é—œå°å…¥ ---
import Levenshtein
import numpy as np
import pandas as pd
import torch
from datasets import Audio, Dataset, DatasetDict
# --- Hugging Face ç›¸é—œå°å…¥ ---
from huggingface_hub import login
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from transformers import (Seq2SeqTrainer, Seq2SeqTrainingArguments,
                          WhisperFeatureExtractor,
                          WhisperForConditionalGeneration, WhisperProcessor,
                          WhisperTokenizer)

# ==============================================================================
# æ­¥é©Ÿ 1: å°‡æ‰€æœ‰è¼”åŠ©é¡åˆ¥èˆ‡å‡½å¼å®šç¾©åœ¨ã€Œå…¨åŸŸç¯„åœã€
# é€™æ˜¯ç‚ºäº†ç¢ºä¿åœ¨ä½¿ç”¨ dataloader_num_workers > 0 æ™‚ï¼ŒèƒŒæ™¯ç¨‹åºå¯ä»¥æˆåŠŸåºåˆ—åŒ– (pickle) å®ƒå€‘ã€‚
# ==============================================================================

# --- å…¨åŸŸè®Šæ•¸ï¼šä¸­æ–‡èªæ„æ¨¡å‹ (é¿å…é‡è¤‡è¼‰å…¥) ---
semantic_model = None

def load_semantic_model():
    """è¼‰å…¥ä¸­æ–‡èªæ„ç›¸ä¼¼åº¦æ¨¡å‹"""
    global semantic_model
    if semantic_model is None:
        print("è¼‰å…¥ä¸­æ–‡èªæ„ç›¸ä¼¼åº¦æ¨¡å‹...")
        semantic_model = SentenceTransformer('shibing624/text2vec-base-chinese')
        print("âœ… èªæ„ç›¸ä¼¼åº¦æ¨¡å‹è¼‰å…¥å®Œæˆ")
    return semantic_model


@dataclass
class DataCollatorSpeechSeq2SeqWithPadding:
    """è™•ç†èªéŸ³åˆ°åºåˆ—è³‡æ–™çš„ Data Collatorï¼Œè² è²¬å°‡æ¨£æœ¬æ•´ç†æˆæ‰¹æ¬¡ä¸¦é€²è¡Œå¡«å……ã€‚"""

    processor: Any

    def __call__(
        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]
    ) -> Dict[str, torch.Tensor]:
        input_features = [
            {"input_features": feature["input_features"]} for feature in features
        ]
        batch = self.processor.feature_extractor.pad(
            input_features, return_tensors="pt"
        )
        label_features = [{"input_ids": feature["labels"]} for feature in features]
        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors="pt")
        labels = labels_batch["input_ids"].masked_fill(
            labels_batch.attention_mask.ne(1), -100
        )
        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():
            labels = labels[:, 1:]
        batch["labels"] = labels
        return batch


def prepare_dataset_batched(batch, feature_extractor, tokenizer):
    """å°‡ä¸€æ‰¹éŸ³è¨Šå’Œæ–‡æœ¬è³‡æ–™ã€å³æ™‚ã€è½‰æ›ç‚ºæ¨¡å‹è¼¸å…¥æ ¼å¼ã€‚"""
    audio_list = batch["audio"]
    batch["input_features"] = feature_extractor(
        [x["array"] for x in audio_list], sampling_rate=audio_list[0]["sampling_rate"]
    ).input_features
    batch["labels"] = tokenizer(
        batch["transcription"], max_length=448, truncation=True
    ).input_ids
    return batch


def compute_cer(predictions, references):
    """è¨ˆç®—å­—å…ƒéŒ¯èª¤ç‡ (Character Error Rate)"""
    total_cer = 0
    total_chars = 0
    
    for pred, ref in zip(predictions, references):
        # è¨ˆç®—ç·¨è¼¯è·é›¢
        edit_distance = Levenshtein.distance(pred, ref)
        # è¨ˆç®— CER
        cer = edit_distance / max(len(ref), 1)  # é¿å…é™¤é›¶
        total_cer += cer
        total_chars += len(ref)
    
    avg_cer = total_cer / len(predictions) if predictions else 0
    return avg_cer

def compute_semantic_similarity(predictions, references):
    """è¨ˆç®—èªæ„ç›¸ä¼¼åº¦"""
    try:
        model = load_semantic_model()
        
        # æ‰¹æ¬¡è¨ˆç®—èªæ„åµŒå…¥
        all_texts = predictions + references
        embeddings = model.encode(all_texts)
        
        # åˆ†å‰²åµŒå…¥å‘é‡
        pred_embeddings = embeddings[:len(predictions)]
        ref_embeddings = embeddings[len(predictions):]
        
        # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
        similarities = []
        for pred_emb, ref_emb in zip(pred_embeddings, ref_embeddings):
            # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
            similarity = cosine_similarity([pred_emb], [ref_emb])[0][0]
            similarities.append(similarity)
        
        avg_similarity = np.mean(similarities) if similarities else 0
        return avg_similarity
        
    except Exception as e:
        print(f"âš ï¸ èªæ„ç›¸ä¼¼åº¦è¨ˆç®—å¤±æ•—: {e}")
        return 0.0

def compute_metrics(pred, tokenizer):
    """åœ¨è©•ä¼°éšæ®µï¼Œè¨ˆç®—ä¸¦å›å‚³ CER å’Œèªæ„ç›¸ä¼¼åº¦æŒ‡æ¨™ã€‚"""
    pred_ids = pred.predictions
    label_ids = pred.label_ids
    
    # è™•ç†å¡«å……æ¨™è¨˜
    label_ids[label_ids == -100] = tokenizer.pad_token_id
    
    # è§£ç¢¼é æ¸¬å’Œåƒè€ƒæ–‡æœ¬
    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)
    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)
    
    # æ¸…ç†æ–‡æœ¬ (ç§»é™¤ç©ºç™½å­—ç¬¦)
    pred_str = [text.strip() for text in pred_str]
    label_str = [text.strip() for text in label_str]
    
    # è¨ˆç®— CER
    cer = compute_cer(pred_str, label_str)
    
    # è¨ˆç®—èªæ„ç›¸ä¼¼åº¦
    semantic_sim = compute_semantic_similarity(pred_str, label_str)
    
    # è¨ˆç®—ç¶œåˆè©•åˆ† (èªæ„ç›¸ä¼¼åº¦ - CERï¼Œè¶Šå¤§è¶Šå¥½)
    combined_score = semantic_sim - cer
    
    return {
        "cer": cer,
        "semantic_similarity": semantic_sim,
        "combined_score": combined_score
    }


# ==============================================================================
# æ­¥é©Ÿ 2: ä¸»åŸ·è¡Œæµç¨‹
# ==============================================================================
def main():
    # --- åƒæ•¸è¨­å®š ---
    CSV_PATH = "youtube_clips_isolated/clips_mapping.csv"
    MODEL_NAME = "openai/whisper-small"
    LANGUAGE = "zh"
    TASK = "transcribe"
    OUTPUT_DIR = "./whisper-small-zh-finetune-zh-final"

    # --- è¼‰å…¥ Processor å’Œæ¨¡å‹ ---
    print("--- æ­¥é©Ÿ 1/4: è¼‰å…¥ Processor å’Œæ¨¡å‹ ---")
    processor = WhisperProcessor.from_pretrained(
        MODEL_NAME, language=LANGUAGE, task=TASK
    )
    model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME)
    model.config.forced_decoder_ids = None
    model.config.suppress_tokens = []

    # --- å»ºç«‹åŸå§‹è³‡æ–™é›† ---
    class AudioDatasetProcessor:
        def __init__(self, file_path: str, target_sampling_rate: int = 16000):
            self.file_path = file_path
            self.target_sampling_rate = target_sampling_rate

        def create_dataset(self) -> Dataset:
            # è®€å– CSV æª”æ¡ˆ
            full_data = pd.read_csv(self.file_path)
            
            # é‡æ–°å‘½åæ¬„ä½ä»¥ç¬¦åˆç¨‹å¼ç¢¼æœŸæœ›çš„æ ¼å¼
            # åŸå§‹æ ¼å¼ï¼šæ¼¢å­—,åŸå§‹åˆ‡ç‰‡,æª”æ¡ˆä½ç½®
            # æœŸæœ›æ ¼å¼ï¼šfile,transcription
            full_data = full_data.rename(columns={
                'æª”æ¡ˆä½ç½®': 'file',  # ä½¿ç”¨éš”é›¢äººè²çš„æª”æ¡ˆ
                'æ¼¢å­—': 'transcription'
            })
            
            # åªä¿ç•™éœ€è¦çš„æ¬„ä½
            full_data = full_data[['file', 'transcription']]
            
            # å»ºç«‹è³‡æ–™é›†
            dataset = Dataset.from_pandas(full_data)
            dataset = dataset.cast_column(
                "file", Audio(sampling_rate=self.target_sampling_rate)
            )
            dataset = dataset.rename_column("file", "audio")
            return dataset

    print("\n--- æ­¥é©Ÿ 2/4: å»ºç«‹åŸå§‹è³‡æ–™é›†ä¸¦è¨­å®šã€å³æ™‚è½‰æ›ã€---")
    audio_processor = AudioDatasetProcessor(file_path=CSV_PATH)
    full_dataset = audio_processor.create_dataset()
    common_voice = full_dataset.train_test_split(test_size=0.2, seed=42)

    # ä½¿ç”¨ .with_transform() ç¢ºä¿è¨˜æ†¶é«”ç©©å®šï¼Œè¨“ç·´èƒ½ç«‹åˆ»é–‹å§‹
    prepare_fn = partial(
        prepare_dataset_batched,
        feature_extractor=processor.feature_extractor,
        tokenizer=processor.tokenizer,
    )
    vectorized_datasets = common_voice.with_transform(prepare_fn)
    print("å³æ™‚è½‰æ›å·²è¨­å®šã€‚")

    # --- å»ºç«‹è¨“ç·´å…ƒä»¶ ---
    print("\n--- æ­¥é©Ÿ 3/4: å»ºç«‹è¨“ç·´å…ƒä»¶ (æœ€çµ‚ç©©å®šé‹è¡Œç‰ˆ) ---")
    data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)
    compute_metrics_fn = partial(compute_metrics, tokenizer=processor.tokenizer)

    # [ä¸­æ–‡å„ªåŒ–ç‰ˆæœ¬]
    # æ ¹æ“šç ”ç©¶çµæœå’Œä¸­æ–‡èªéŸ³è¾¨è­˜éœ€æ±‚èª¿æ•´çš„è¨“ç·´åƒæ•¸
    training_args = Seq2SeqTrainingArguments(
        output_dir=OUTPUT_DIR,
        # 1. å¤§å¹…é™ä½æ‰¹æ¬¡å¤§å°ï¼Œé€™æ˜¯é¿å… OOM çš„æ ¸å¿ƒ
        per_device_train_batch_size=4,  # å¾ 32 æˆ– 16 å¤§å¹…é™è‡³ 4ï¼Œé€™æ˜¯ä¸€å€‹æ¥µåº¦å®‰å…¨çš„å€¼
        per_device_eval_batch_size=4,  # é©—è­‰æ‰¹æ¬¡ä¹Ÿä½¿ç”¨åŒæ¨£çš„å®‰å…¨å€¼
        # 2. é©åº¦ä½¿ç”¨æ¢¯åº¦ç´¯ç©ï¼Œä»¥ç©©å®šè¨“ç·´
        # æœ‰æ•ˆæ‰¹æ¬¡å¤§å°ç‚º 4 * 4 = 16ï¼Œé€™æ˜¯ä¸€å€‹ä¸éŒ¯çš„å¹³è¡¡é»
        gradient_accumulation_steps=4,
        # 3. ç¦ç”¨å¤šæ ¸å¿ƒè™•ç†ï¼Œé€™æ˜¯ç¢ºä¿ç¨‹å¼ä¸è¢«æ›èµ·çš„é—œéµ
        dataloader_num_workers=0,
        # --- å…¶ä»–åƒæ•¸ç¶­æŒä¸è®Š ---
        learning_rate=1e-5,
        warmup_steps=5,                 # æ¸¬è©¦ç”¨ï¼šæ¸›å°‘é ç†±æ­¥æ•¸
        max_steps=10,                   # æ¸¬è©¦ç”¨ï¼š10æ­¥é©—è­‰æµç¨‹
        # --- è©•ä¼°èˆ‡ä¿å­˜è¨­å®š ---
        gradient_checkpointing=False,
        fp16=True,
        eval_strategy="steps",
        predict_with_generate=True,
        generation_max_length=225,
        save_steps=200,                 # æ›´é »ç¹ä¿å­˜ï¼Œå¿«é€Ÿå±•ç¤ºç”¨
        eval_steps=5,                   # æ¸¬è©¦ç”¨ï¼šæ¯5æ­¥è©•ä¼°
        logging_steps=25,
        report_to=["tensorboard"],
        # --- æœ€ä½³æ¨¡å‹é¸æ“‡ï¼šä½¿ç”¨ç¶œåˆè©•åˆ† ---
        load_best_model_at_end=True,
        metric_for_best_model="combined_score",  # ä½¿ç”¨ç¶œåˆè©•åˆ†
        greater_is_better=True,         # ç¶œåˆè©•åˆ†è¶Šå¤§è¶Šå¥½
        push_to_hub=True,
        remove_unused_columns=False,
    )
    trainer = Seq2SeqTrainer(
        args=training_args,
        model=model,
        train_dataset=vectorized_datasets["train"],
        eval_dataset=vectorized_datasets["test"],
        data_collator=data_collator,
        compute_metrics=compute_metrics_fn,
        tokenizer=processor.feature_extractor,
    )

    # --- é–‹å§‹è¨“ç·´ ---
    print("\n--- æ­¥é©Ÿ 4/4: é–‹å§‹ä¸­æ–‡èªéŸ³è¾¨è­˜æ¨¡å‹å¾®èª¿è¨“ç·´ ---")
    print("ğŸ“Š è©•ä¼°æŒ‡æ¨™ï¼šCER (è¶Šä½è¶Šå¥½) + èªæ„ç›¸ä¼¼åº¦ (è¶Šé«˜è¶Šå¥½) + ç¶œåˆè©•åˆ†")
    print("ğŸš€ è¨“ç·´æ­¥æ•¸ï¼š10æ­¥ (æ¸¬è©¦ç”¨ï¼Œé©—è­‰è¨“ç·´æµç¨‹)")
    print("â±ï¸ é ä¼°æ™‚é–“ï¼šç´„ 30 ç§’ (å¿«é€Ÿæ¸¬è©¦)")
    # ä¸å¸¶åƒæ•¸çš„ .train() æœƒè‡ªå‹•è™•ç†æ–·é»çºŒç·´ï¼Œæ˜¯æœ€ç©©å¥çš„åšæ³•ã€‚
    trainer.train()
    print("\n*** ä¸­æ–‡èªéŸ³è¾¨è­˜æ¨¡å‹è¨“ç·´å®Œæˆ ***")

    # --- å„²å­˜æœ€çµ‚æ¨¡å‹ ---
    print("\n--- æ­£åœ¨å„²å­˜æœ€çµ‚çš„æœ€ä½³æ¨¡å‹ ---")
    final_model_path = training_args.output_dir
    trainer.save_model(final_model_path)
    processor.save_pretrained(final_model_path)
    print(f"\næœ€çµ‚æ¨¡å‹å·²å„²å­˜è‡³ï¼š{final_model_path}")


if __name__ == "__main__":
    # ç¢ºä¿æ‚¨å·²åœ¨çµ‚ç«¯æ©Ÿä½¿ç”¨ `huggingface-cli login` ç™»å…¥
    # åŸ·è¡Œå‰å»ºè­°é‡æ–°å•Ÿå‹•æ‚¨çš„é›»è…¦ï¼Œç¢ºä¿ç³»çµ±è™•æ–¼ä¹¾æ·¨ç‹€æ…‹
    main()
